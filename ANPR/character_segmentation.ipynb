{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../images/license10.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "image = cv2.resize(image, (600, 200))\n",
    "\n",
    "equalized = cv2.equalizeHist(image)\n",
    "\n",
    "\n",
    "plt.imshow(equalized, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast stretching\n",
    "# contrast_image = cv2.equalizeHist(image)\n",
    "\n",
    "# clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "# contrast_image = clahe.apply(image)\n",
    "\n",
    "# plt.imshow(contrast_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(image,(5,5),0)\n",
    "# thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 2)\n",
    "# plt.imshow(thresh, cmap='gray')\n",
    "\n",
    "ret, thresh = cv2.threshold(blurred,125,255, cv2.THRESH_BINARY)\n",
    "plt.imshow(thresh, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = cv2.connectedComponents(thresh)\n",
    "mask = np.zeros(thresh.shape, dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pixels = image.shape[0] * image.shape[1]\n",
    "lower = 100\n",
    "upper = total_pixels * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the unique components\n",
    "for (i, label) in enumerate(np.unique(labels)):\n",
    "    # label 0 vaneko background ho\n",
    "    if label == 0:\n",
    "        continue\n",
    "\n",
    "    # otherwise construct the label mask to display only connected component\n",
    "    # for the current label\n",
    "    labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "    labelMask[labels == label] = 255\n",
    "    numPixels = cv2.countNonZero(labelMask)\n",
    "\n",
    "    # Get the bounding box of the connected component\n",
    "    (y, x) = np.where(labels == label)\n",
    "    (topY, topX) = (np.min(y), np.min(x))\n",
    "    (bottomY, bottomX) = (np.max(y), np.max(x))\n",
    "    width = bottomX - topX\n",
    "    height = bottomY - topY\n",
    "\n",
    "    # filtering the bounding box\n",
    "    if width > 250 or height > 250:\n",
    "        continue\n",
    "\n",
    "    # more filtering\n",
    "    if width > 20 and height > 20:\n",
    "        if numPixels > lower and numPixels < upper:\n",
    "            mask = cv2.add(mask, labelMask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours and get bounding box for each contour\n",
    "contours, hierarchy= cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "boundingBoxes = [cv2.boundingRect(c) for c in contours]\n",
    "boundingBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the bounding boxes from left to right, top to bottom\n",
    "# sort by Y first, and then sort by X if Ys are similar\n",
    "def compare(rect1, rect2):\n",
    "    if abs(rect1[1] - rect2[1]) > 10:\n",
    "        return rect1[1] - rect2[1]\n",
    "    else:\n",
    "        return rect1[0] - rect2[0]\n",
    "boundingBoxes = sorted(boundingBoxes, key=functools.cmp_to_key(compare) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundingBoxes = [bbox for bbox in boundingBoxes if bbox[2] * bbox[3] > 1600]\n",
    "boundingBoxes = [bbox for bbox in boundingBoxes if bbox[2] * bbox[3] > 1300 and bbox[2] / bbox[3] <= 4 and bbox[3] / bbox[2] <= 4]\n",
    "print(boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread(image_path)\n",
    "test = cv2.cvtColor(test,cv2.COLOR_BGR2RGB)\n",
    "test = cv2.resize(test, (600, 200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, bbox in enumerate(boundingBoxes):\n",
    "    x, y, w, h = bbox\n",
    "    if x > 5 and y > 10:\n",
    "            padding = 10\n",
    "    else:\n",
    "            padding = 0\n",
    "    padding = 0\n",
    "    cropped_image = test[y-padding:y+h+padding, x-padding:x+w+padding]\n",
    "    cv2.imwrite(f'./results/cropped_image_{i}.png', cropped_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bbox in boundingBoxes:\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(test, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('./results/final_image.png', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     cv2.imshow('mask',mask_image_resized)\n",
    "#     if cv2.waitKey(10) & 0xFF == 27:\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
