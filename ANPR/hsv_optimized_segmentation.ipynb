{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path  = \"./images/license17.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (600,200))\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "original_image = image.copy()\n",
    "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "# image to segment will be in final_original_image below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(original_image)\n",
    "plt.title('Original Image RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "plt.imshow(hsv_image)\n",
    "plt.title('HSV Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,s,v = cv2.split(hsv_image)\n",
    "\n",
    "# clahe equalization on hsv\n",
    "clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))\n",
    "equalized_v = clahe.apply(v)\n",
    "merged_hsv = cv2.merge([h,s,equalized_v])\n",
    "equalized_bgr = cv2.cvtColor(merged_hsv, cv2.COLOR_HSV2BGR)\n",
    "plt.imshow(cv2.cvtColor(equalized_bgr, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Equalized Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower boundary RED color range values; Hue (0 - 10)\n",
    "lower1 = np.array([0, 100, 100])\n",
    "upper1 = np.array([10, 255, 255])\n",
    " \n",
    "# upper boundary RED color range values; Hue (160 - 180)\n",
    "lower2 = np.array([160,100,100])\n",
    "upper2 = np.array([179,255,255])\n",
    "\n",
    "mask1 = cv2.inRange(hsv_image, lower1, upper1)\n",
    "mask2 = cv2.inRange(hsv_image, lower2, upper2)\n",
    "\n",
    "red_mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "# Define lower and upper bounds for black color in HSV\n",
    "# For black colors in HSV  hue at maximum range (0 to 180), and saturation at maximum range (0 to 255) can play with the value 0 to 30 or 50 for black\n",
    "# if the image has very light black color then increase the value to 100 or less than 120\n",
    "lower_black = np.array([0, 0, 0])\n",
    "upper_black = np.array([180, 60, 60])\n",
    "\n",
    "# Create a mask for black color\n",
    "mask_black = cv2.inRange(hsv_image, lower_black, upper_black)\n",
    "\n",
    "multi_color_mask = cv2.bitwise_or(red_mask, mask_black)\n",
    "\n",
    "plt.figure(figsize=(12, 6))  # Set the figure size to large\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(red_mask, cmap='gray')\n",
    "plt.title('Red Mask')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask_black, cmap='gray')\n",
    "plt.title(\"Black Mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masked_image = cv2.bitwise_and(original_image, equalized_bgr, mask=multi_color_mask)\n",
    "plt.imshow(masked_image)\n",
    "plt.title('Masked Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image, pts):\n",
    "    # Get the maximum width and height\n",
    "    max_width = max(np.linalg.norm(pts[0] - pts[1]), np.linalg.norm(pts[2] - pts[3]))\n",
    "    max_height = max(np.linalg.norm(pts[0] - pts[3]), np.linalg.norm(pts[1] - pts[2]))\n",
    "\n",
    "    # Set destination points\n",
    "    dst_pts = np.array([[0, 0], [max_width - 1, 0], [max_width - 1, max_height - 1], [0, max_height - 1]], dtype='float32')\n",
    "\n",
    "    # Calculate perspective transform matrix\n",
    "    matrix = cv2.getPerspectiveTransform(pts, dst_pts)\n",
    "\n",
    "    # Apply perspective transform\n",
    "    result = cv2.warpPerspective(image, matrix, (int(max_width), int(max_height)))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_pixels = cv2.countNonZero(red_mask)\n",
    "black_pixels = cv2.countNonZero(mask_black)\n",
    "\n",
    "print(f\"Red pixels: {red_pixels}\")\n",
    "print(f\"Black pixels: {black_pixels}\")\n",
    "\n",
    "if red_pixels > black_pixels:\n",
    "    dominant_color = 'red'\n",
    "    dominant_mask = red_mask\n",
    "else:\n",
    "    dominant_color = 'black'\n",
    "    dominant_mask = mask_black\n",
    "\n",
    "contours, hierarchy = cv2.findContours(dominant_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "if contours:\n",
    "    # Sort contours by area and get the largest contour\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Approximate a minimum rectangle around the largest contour\n",
    "    rect = cv2.minAreaRect(largest_contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.intp(box)\n",
    "\n",
    "    # Convert box points to float32\n",
    "    box = box.astype(np.float32)\n",
    "\n",
    "    # Perform perspective transform\n",
    "    transformed_image = perspective_transform(image, box)\n",
    "\n",
    "if transformed_image.shape[0] > transformed_image.shape[1]:\n",
    "    transformed_image = cv2.rotate(transformed_image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "resized_image = cv2.resize(transformed_image, (600, 200))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(transformed_image)\n",
    "plt.title('Transformed Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resized_image)\n",
    "plt.title(\"Transformed and resized image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the resized image\n",
    "resized_image.shape\n",
    "final_original_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(final_original_image)\n",
    "plt.title(\"Final image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_white = np.array([0,150,150])\n",
    "upper_white = np.array([255,255,255])\n",
    "\n",
    "white_mask = cv2.inRange(final_original_image, lower_white, upper_white)\n",
    "masked_image = cv2.bitwise_and(final_original_image, final_original_image, mask=white_mask)\n",
    "\n",
    "test = cv2.bitwise_and(final_original_image,masked_image)\n",
    "\n",
    "plt.imshow(white_mask,cmap=\"gray\")\n",
    "\n",
    "\n",
    "# send masked_white or final_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_process = cv2.cvtColor(final_original_image, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(image_process, cmap=\"gray\")\n",
    "plt.title('Gray Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clahe histogram\n",
    "# clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))\n",
    "# image_process_equalized = clahe.apply(image_process)\n",
    "# plt.imshow(image_process_equalized, cmap=\"gray\")\n",
    "\n",
    "# adaptive histogram\n",
    "# image_process_equalized = cv2.equalizeHist(image_process)\n",
    "# plt.imshow(image_process_equalized, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),dtype=np.uint8)\n",
    "blurred_image = cv2.GaussianBlur(image_process, (5,5), 0)\n",
    "plt.imshow(blurred_image, cmap=\"gray\")\n",
    "plt.title(\"After blur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_process_hist = cv2.calcHist([blurred_image], [0], None, [256], [0, 256])\n",
    "plt.plot(calc_process_hist)\n",
    "plt.title(\"Histogram of process image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh option 1\n",
    "# ret, thresh = cv2.threshold(image_process,140,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# thresh option 2\n",
    "ret, thresh = cv2.threshold(blurred_image,120,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title(\"Threshold image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "erode = cv2.erode(thresh, kernel, iterations=1)\n",
    "\n",
    "plt.imshow(erode, cmap='gray')\n",
    "# thresh = equalized_morphed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_size = 10\n",
    "border_color = (0, 0, 0)  # black color\n",
    "\n",
    "# Add border to the image\n",
    "# cv2.rectangle(thresh, (0, 0), (thresh.shape[1], thresh.shape[0]), border_color, border_size)\n",
    "\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title('Image with Border')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = cv2.connectedComponents(thresh)\n",
    "mask = np.zeros(thresh.shape, dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pixels = image.shape[0] * image.shape[1]\n",
    "lower = 300\n",
    "upper = total_pixels * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the unique components\n",
    "for (i, label) in enumerate(np.unique(labels)):\n",
    "    # label 0 vaneko background ho\n",
    "    if label == 0:\n",
    "        continue\n",
    "\n",
    "    # otherwise construct the label mask to display only connected component\n",
    "    # for the current label\n",
    "    labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "    labelMask[labels == label] = 255\n",
    "    numPixels = cv2.countNonZero(labelMask)\n",
    "\n",
    "    # Get the bounding box of the connected component\n",
    "    (y, x) = np.where(labels == label)\n",
    "    (topY, topX) = (np.min(y), np.min(x))\n",
    "    (bottomY, bottomX) = (np.max(y), np.max(x))\n",
    "    width = bottomX - topX\n",
    "    height = bottomY - topY\n",
    "\n",
    "\n",
    "    # filtering the bounding box\n",
    "    if width > 180 or height > 140:\n",
    "        continue\n",
    "\n",
    "    # filtering if the width and height is more than 100px but has less pixel values\n",
    "    if width > 100 and height > 100 and numPixels < 2000:\n",
    "        continue\n",
    "\n",
    "    # more filtering\n",
    "    if width > 20 and height > 20:\n",
    "        # print(width, height, numPixels)\n",
    "        if numPixels > lower and numPixels < upper:\n",
    "            # Check if the line starts from the top and ends at more than half the height\n",
    "            mask = cv2.add(mask, labelMask)\n",
    "            print(topX, topY, bottomX, bottomY,width,height,numPixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask,cmap='gray')\n",
    "plt.title(\"After cleaning image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contours, hierarchy= cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# boundingBoxes = [cv2.boundingRect(c) for c in contours]\n",
    "contours, hierarchy = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "boundingBoxes = [cv2.boundingRect(c) for c in contours if cv2.contourArea(c) > 1000]\n",
    "\n",
    "print(boundingBoxes)\n",
    "\n",
    "boundingBoxes = [bbox for bbox in boundingBoxes if bbox[2] / bbox[3] <= 3 and bbox[3] / bbox[2] <= 4]\n",
    "\n",
    "for c in contours:\n",
    "    print(cv2.contourArea(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(rect1, rect2):\n",
    "    if abs(rect1[1] - rect2[1]) > 30:\n",
    "        return rect1[1] - rect2[1]\n",
    "    else:\n",
    "        return rect1[0] - rect2[0]\n",
    "boundingBoxes = sorted(boundingBoxes, key=functools.cmp_to_key(compare) )\n",
    "print(boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, bbox in enumerate(boundingBoxes):\n",
    "    x, y, w, h = bbox\n",
    "    if x > 10 and y > 10:\n",
    "            padding = 10\n",
    "    else:\n",
    "            padding = 0\n",
    "    padding = 0\n",
    "    cropped_image = final_original_image[y-padding:y+h+padding, x-padding:x+w+padding]\n",
    "    cropped_resized = cv2.resize(cropped_image, (64,64))\n",
    "    cropped_resized = cv2.cvtColor(cropped_resized, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(f'./ch/character_{i}.png', cropped_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bbox in boundingBoxes:\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(final_original_image, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "plt.imshow(final_original_image)\n",
    "cv2.imwrite('final_image.jpg',final_original_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
